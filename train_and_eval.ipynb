{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b22c88ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils.MNIST_loaders import MNIST_loaders\n",
    "\n",
    "from functions.train import train\n",
    "from functions.evaluate import evaluate\n",
    "\n",
    "from models.HypernetClassifier import HyperNetClassifier\n",
    "from models.Classifier import Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e57248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hyperparameters ---\n",
    "num_epochs = 5\n",
    "batch_size = 64\n",
    "weight_decay = 0.001\n",
    "validation_split = 0.2  # Part of the training data to use for validation\n",
    "random_seed = 42\n",
    "n_bins = 10 # Number of bins for calculating ECE\n",
    "input_size = 28 * 28\n",
    "output_size = 10\n",
    "\n",
    "learning_rate = 0.0003\n",
    "optimizer = 'SGD'\n",
    "hidden_size = [256, 128, 256]\n",
    "zeroed_weights_in_baseline = 0.5\n",
    "hypernet_ensemble_num = 10\n",
    "use_previous_weights = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54f26b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(random_seed)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8f0c85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training [A: Accuracy, L: Loss, ECE: Expected Calibration Error, H: Hypernet]\n",
      "\n",
      "=== Epoch: [1|5] ========================\n",
      "Train: L: 1.5616, H_L: 11.3475, A: 57.81%, H_A: 60.53%\n",
      "Val: A: 74.90%, A_H: 87.61%, ECE: 0.32406, ECE_H: 0.07129\n",
      "\n",
      "=== Epoch: [2|5] ========================\n",
      "Train: L: 0.9127, H_L: 6.6120, A: 77.96%, H_A: 77.39%\n",
      "Val: A: 80.01%, A_H: 88.79%, ECE: 0.21491, ECE_H: 0.06259\n",
      "\n",
      "=== Epoch: [3|5] ========================\n",
      "Train: L: 0.7057, H_L: 6.4858, A: 81.57%, H_A: 78.15%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m avg_loss, avg_hypernet_loss, accuracy, hypernet_accuracy \u001b[38;5;241m=\u001b[39m train(model, hypernet_model, train_loader, optimizer, hypernet_optimizer, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain: L: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, H_L: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_hypernet_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, A: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%, H_A: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhypernet_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m val_accuracy, ece \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_bins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_bins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m hypernet_val_accuracy, hypernet_ece \u001b[38;5;241m=\u001b[39m evaluate(hypernet_model, val_loader, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal: A: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%, A_H: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhypernet_val_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%, ECE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mece\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, ECE_H: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhypernet_ece\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lewy7\\Documents\\GitHub\\hypernets\\functions\\evaluate.py:42\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model, data_loader, n_bins, device)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_bins):\n\u001b[0;32m     41\u001b[0m     in_bin \u001b[38;5;241m=\u001b[39m (confidences \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m bin_lowers[i]) \u001b[38;5;241m&\u001b[39m (confidences \u001b[38;5;241m<\u001b[39m bin_uppers[i])\n\u001b[1;32m---> 42\u001b[0m     bin_totals[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43min_bin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     bin_corrects[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (accuracies[in_bin])\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     44\u001b[0m     bin_confidences[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (confidences[in_bin])\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Classifier(input_size, output_size, zeroed_weights_fraction=zeroed_weights_in_baseline)\n",
    "hypernet_model = HyperNetClassifier(input_size, output_size, hidden_sizes=hidden_size, device=device, use_previous_weights=use_previous_weights, ensemble_num=hypernet_ensemble_num)\n",
    "\n",
    "if optimizer == 'SGD':\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    hypernet_optimizer = optim.SGD(hypernet_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "else:\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    hypernet_optimizer = optim.Adam(hypernet_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "train_loader, val_loader, test_loader = MNIST_loaders()\n",
    "\n",
    "print(\"Starting Training [A: Accuracy, L: Loss, ECE: Expected Calibration Error, H: Hypernet]\")\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    \n",
    "    print(f\"\\n=== Epoch: [{epoch}|{num_epochs}] ========================\")\n",
    "    \n",
    "    avg_loss, avg_hypernet_loss, accuracy, hypernet_accuracy = train(model, hypernet_model, train_loader, optimizer, hypernet_optimizer, device=device)\n",
    "    print(f'Train: L: {avg_loss:.4f}, H_L: {avg_hypernet_loss:.4f}, A: {accuracy:.2f}%, H_A: {hypernet_accuracy:.2f}%')\n",
    "    \n",
    "    val_accuracy, ece = evaluate(model, val_loader, n_bins=n_bins, device=device)\n",
    "    hypernet_val_accuracy, hypernet_ece = evaluate(hypernet_model, val_loader, device=device)\n",
    "    print(f'Val: A: {val_accuracy:.2f}%, A_H: {hypernet_val_accuracy:.2f}%, ECE: {ece:.5f}, ECE_H: {hypernet_ece:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554bd387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Testing...\n",
      "Normal Model:\n",
      "Test set: Accuracy: 91.31%, ECE: 0.04334\n",
      "Hypernet Model:\n",
      "Test set: Accuracy: 91.07%, ECE: 0.01071\n"
     ]
    }
   ],
   "source": [
    "# --- Testing the Model ---\n",
    "print(\"\\nStarting Testing...\")\n",
    "\n",
    "print(\"Normal Model:\")\n",
    "test_accuracy, ece = evaluate(model, test_loader, n_bins=n_bins, device=device)\n",
    "print(f'Test set: Accuracy: {test_accuracy:.2f}%, ECE: {ece:.5f}')\n",
    "\n",
    "print(\"Hypernet Model:\")\n",
    "test_accuracy, ece = evaluate(hypernet_model, test_loader, n_bins=n_bins, device=device)\n",
    "print(f'Test set: Accuracy: {test_accuracy:.2f}%, ECE: {ece:.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
